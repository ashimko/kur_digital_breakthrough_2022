{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_text  # noqa\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "import config as cfg\n",
    "import gc\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from helper import check_path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 768\n",
    "BATCH_SIZE = 128\n",
    "EMB_NAME = 'smaller_LaBSE_15lang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 13:58:26.247176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.279620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.279784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.280549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-22 13:58:26.281128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.281276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.281392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.780663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.780849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.780981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 13:58:26.781083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5379 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sentences (InputLayer)         [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'input_type_ids':   0           ['sentences[0][0]']              \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'sequence_output':  219171840   ['keras_layer_1[0][0]',          \n",
      "                                 (None, 128, 768),                'keras_layer_1[0][1]',          \n",
      "                                 'encoder_outputs':               'keras_layer_1[0][2]']          \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768)}                                                       \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize (TFOpLamb  (None, 768)         0           ['keras_layer[0][12]']           \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 219,171,840\n",
      "Trainable params: 0\n",
      "Non-trainable params: 219,171,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Loading models from tfhub.dev\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang/1\")\n",
    "preprocessor = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/smaller_LaBSE_15lang_preprocess/1\")\n",
    "\n",
    "# Constructing model to encode texts into high-dimensional vectors\n",
    "sentences = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"sentences\")\n",
    "encoder_inputs = preprocessor(sentences)\n",
    "sentence_representation = encoder(encoder_inputs)[\"pooled_output\"]\n",
    "normalized_sentence_representation = tf.nn.l2_normalize(sentence_representation, axis=-1)  # for cosine similarity\n",
    "model = tf.keras.Model(sentences, normalized_sentence_representation)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(cfg.ORIG_TRAIN_PATH).set_index('id')\n",
    "test = pd.read_csv(cfg.ORIG_TEST_PATH).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: pd.Series, emb_name='') -> pd.DataFrame:\n",
    "    n = len(text)\n",
    "    embeddings = np.zeros(shape=(n, EMB_SIZE))\n",
    "    for i in tqdm(range(0, n, BATCH_SIZE), total=n // BATCH_SIZE):\n",
    "        sentences = tf.constant(text.iloc[i:i+BATCH_SIZE].tolist())\n",
    "        embeddings[i:i+BATCH_SIZE, :] = model(sentences)\n",
    "    embeddings = pd.DataFrame(\n",
    "        embeddings, \n",
    "        columns=[f'{emb_name}_{c}' for c in range(EMB_SIZE)],\n",
    "        index=text.index)\n",
    "    return embeddings    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bd9aa0e8524619a08d86da87e37a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e650fb78a64a679258d563474742ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_embeddings = get_embedding(train[cfg.TEXT_COL], emb_name=EMB_NAME)\n",
    "test_embeddings = get_embedding(test[cfg.TEXT_COL], emb_name=EMB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_path = os.path.join(cfg.DATA_PATH, EMB_NAME)\n",
    "check_path(emb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings.to_pickle(os.path.join(emb_path, 'train.pkl'))\n",
    "test_embeddings.to_pickle(os.path.join(emb_path, 'test.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5356ef1c2ac2ef25d35a0579f082f1d273c4bada2fe955fa1b70f42402fff98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
